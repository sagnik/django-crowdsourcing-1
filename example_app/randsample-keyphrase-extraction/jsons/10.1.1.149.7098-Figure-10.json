{"Caption":"Figure 10: The particular local descriptors used pro- vided a bias to the types of patterns found. These images, selected by our approach, received the most \u201Cirrelevant\u201D votes from the users for the queries shown. ","ImageText":[{"Text":"(a)","TextBB":[103.666,713.493,119.986,725.947],"Rotation":0},{"Text":"dell","TextBB":[129.342,713.493,149.216,725.947],"Rotation":0},{"Text":"puter","TextBB":[103.666,725.993,133.675,738.447],"Rotation":0},{"Text":"com-","TextBB":[165.327,713.493,192.264,725.947],"Rotation":0},{"Text":"(b)","TextBB":[196.5,713.493,213.652,725.947],"Rotation":0},{"Text":"nintendo","TextBB":[236.341,713.493,285.239,725.947],"Rotation":0},{"Text":"(c)","TextBB":[294,713.493,309.655,725.947],"Rotation":0},{"Text":"8800","TextBB":[313.843,713.493,339.248,725.947],"Rotation":0},{"Text":"Ultra","TextBB":[343.682,713.493,373.251,725.947],"Rotation":0},{"Text":"wii","TextBB":[196.5,725.993,212.706,738.447],"Rotation":0},{"Text":"system","TextBB":[217.151,725.993,255.297,738.447],"Rotation":0},{"Text":"(d)","TextBB":[113.166,873.66,130.318,886.113],"Rotation":0},{"Text":"keychain","TextBB":[134.507,873.66,182.936,886.113],"Rotation":0},{"Text":"(e)","TextBB":[196.5,873.66,212.15,886.113],"Rotation":0},{"Text":"ps","TextBB":[216.005,873.66,228.215,886.113],"Rotation":0},{"Text":"2","TextBB":[231.166,873.66,237.567,886.113],"Rotation":0},{"Text":"network","TextBB":[240.5,873.66,284.917,886.113],"Rotation":0},{"Text":"(f)","TextBB":[289.333,873.66,304.151,886.113],"Rotation":0},{"Text":"dell","TextBB":[313.839,873.66,333.714,886.113],"Rotation":0},{"Text":"adapter","TextBB":[196.5,886.16,239.178,898.613],"Rotation":0},{"Text":"puter","TextBB":[289.333,886.16,319.342,898.613],"Rotation":0},{"Text":"com-","TextBB":[350.825,873.66,377.761,886.113],"Rotation":0}],"Mention":["querying \u201CApple\u201D did they want the fruit or the computer?).\nSecond, we did not ask the users to compare two sets; since,\nas mentioned earlier, this is an arduous task. Instead, the\nuser was asked to examine each image individually. Third,\nthe user was given no indication of ranking; thereby allevi-\nating the burden of analyzing image ordering.\nIt is also worth noting that minimizing the number of ir-\nrelevant images is important in real-world usage scenarios\nbeyond \u201Ctraditional\u201D image search. In many uses, we need\nto select a very small set (1-3) of images to show from poten-\ntially millions of images. Unlike ranking, the goal is not to\nreorder the full set of images, but to select only the \u201Cbest\u201D\nones to show. Two concrete usage cases for this are: 1.\nGoogle product search: only a single image is shown for each\nproduct returned in response to a product query; shown in\nFigure 8(a). 2. Mixed-Result-Type Search: to indicate that\nimage results are available when a user performs a web (web-\npage) query, a small set of representative images may also\nbe shown to entice the user to try the image search as shown\nin Figure 8(b). In both of these examples, it is paramount\nthat the user is not shown irrelevant, off-topic, images. Both\nof these scenarios benefit from procedures that perform well\non this experimental setup.\nWe measured the results at three settings: the number\nof irrelevant images in the top-10, top-5, and top-3 images\nreturned by each of the algorithms. Table 1 contains the\ncomparison results. Among the top 10 images, we produced\nan average of 0.47 irrelevant results, this is compared with\n2.82 by Google; this represents an 83% drop in irrelevant\nimages. When looking at the top-3 images, the number of\nirrelevant images dropped to 0.2, while Google dropped to\n0.81.\nIn terms of overall performance on queries, the proposed\napproach contains less irrelevant images than Google for 762\nqueries. In only 70 queries did Google\u2019s standard image\nsearch produce better results. In the remaining 202 queries,\nboth approaches tied (in the majority of these, there were no\nirrelevant images). Figure 9 shows examples of top ranking\nresults for a collection of queries. Aside from the generally\nintuitive results shown in Figure 9, an interesting result is\nshown for the query \u201CPicasso Paintings\u201D; not only are all the\nimages by Picasso, one of his most famous, \u201CGuernica\u201D, was\nselected first.\nTo present a complete analysis, we describe two cases that\ndid not perform as expected. Our approach sometimes fails\nto retrieve relevant images as shown in Figure 10. The first\nthree images are the logos of the company which manufac-\ntured the product being searched for. Although the logo is\nsomewhat related to the query, the evaluators did not regard\nthem as relevant to the specific product for which they were\nsearching. The inflated logo score occurs for two reasons.\nFirst, many product images contains the company logos; ei-\nther within the product itself or in addition to the product.\nIn fact, extra care is often given to make sure that the logos\nare clearly visible, prominent, and uniform in appearance.\n"],"Page":8,"Number":10,"Type":"Figure","CaptionBB":[71,917,407,989],"Height":1100,"Width":850,"DPI":100,"ImageBB":[101,648,379,900]}