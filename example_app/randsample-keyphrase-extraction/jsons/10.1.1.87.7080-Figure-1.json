{"Caption":"Figure 1: Evolving ROBO C ARE demonstrators.","ImageText":[{"Text":"(a)","TextBB":[155.262,373.182,169.084,384.465],"Rotation":0},{"Text":"The","TextBB":[172.199,373.182,191.566,384.465],"Rotation":0},{"Text":"\u201Csilent","TextBB":[194.673,373.182,227.184,384.465],"Rotation":0},{"Text":"observer\u201D","TextBB":[230.296,373.182,278.513,384.465],"Rotation":0},{"Text":"(b)","TextBB":[350.688,373.182,365.209,384.465],"Rotation":0},{"Text":"The","TextBB":[368.324,373.182,387.691,384.465],"Rotation":0},{"Text":"current","TextBB":[390.798,373.182,426.06,384.465],"Rotation":0},{"Text":"robotic","TextBB":[429.172,373.182,464.45,384.465],"Rotation":0},{"Text":"assistant","TextBB":[467.57,373.182,509.781,384.465],"Rotation":0},{"Text":"(c)","TextBB":[566.5,373.182,580.322,384.465],"Rotation":0},{"Text":"The","TextBB":[583.437,373.182,602.804,384.465],"Rotation":0},{"Text":"\u201Cproactive","TextBB":[605.911,373.182,657.264,384.465],"Rotation":0},{"Text":"interactor\u201D","TextBB":[660.384,373.182,713.625,384.465],"Rotation":0}],"Mention":["employed to trigger system initiatives.\nIn parallel with research on the home environment that\n\u201Cobserves a person\u201D the project has worked on setting up\nan autonomous robotic platform able to robustly behave in\na home environment. Our colleagues from the University\nof Rome \u201CLa Sapienza\u201D have set up a Pioneer 2 platform\nwith a Sick laser scanner for localization. Additional work\nhas been requested to both integrate advanced SLAM al-\ngorithms (Grisetti, Stachniss, & Burgard 2005) and obtain\nrobust navigation abilities by integrating a topological path\nplanning and a reactive obstacle avoidance module. We\nsummarize the situation of the robotic platform with what\nis referred to as \u201Crobot motion skills\u201D in the lower part of\nFigure 1(b).\n","The choice has been to move from a \u201Csilent observer\u201D to\nan \u201Cactive interactor\u201D that could spontaneously decide to in-\ntervene in the scene and interact with users. The robot\u2019s abil-\nity to independently move within the environment inspired\nour next steps in the development of the intelligent assis-\ntant. The robot was the natural candidate to be in charge of\nmanaging interaction with the assisted person. Therefore we\nhave enhanced the robot with an additional level of compe-\ntence, referred to as \u201Cinteractive skills\u201D in Figure 1(b), which\ngroup and provide access to the capabilities of the overall in-\ntelligent system.\nThe sketchy view in Figure 1(c) shows how the interaction\nskills integrate the capability of the T-REXActivityMonitor,\nwith a simplified Interaction Manager and a front-end for\nthe interaction module consisting in a Talking Head and a\nSpeech Recognition subsystem. The\u201Ctalking head\u201D, called\nLucia6 is also endowed with speech synthesis functionalities\nbased on the elaboration of a specific \u201Ccontent files\u201D in text\nformat.\n"],"Page":2,"Number":1,"Type":"Figure","CaptionBB":[302,396,546,411],"Height":1169,"Width":826,"DPI":100,"ImageBB":[131,65,722,386]}