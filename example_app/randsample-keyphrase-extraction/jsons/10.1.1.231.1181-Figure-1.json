{"Caption":"Figure 1: An agent creates options using skill chaining. (a) First, the agent encounters a target event and creates an option to reach it. (b) Entering the initiation set of this first option triggers the creation of a second option whose target is the initiation set of the first option. (c) Finally, after many trajectories the agent has created a chain of options to reach the original target. (d) When multiple options are created to target an initiation set, the chain splits and the agent creates a skill tree. ","ImageText":[{"Text":"(a)","TextBB":[211.124,911.213,226.483,923.583],"Rotation":0},{"Text":"(b)","TextBB":[348.345,911.213,364.478,923.583],"Rotation":0},{"Text":"(c)","TextBB":[486.327,911.213,501.686,923.583],"Rotation":0},{"Text":"(d)","TextBB":[623.548,911.213,639.681,923.583],"Rotation":0}],"Mention":["slowly learn a chain of skills that grows backward from the task goal region towards the start region\n(as depicted in Figure 1). More generally, multiple trajectories, noise in control, stochasticity in the\nenvironment, or simple variance will result in skill trees rather than skill chains because more than\none option will be created to reach some target events. Eventually, the entire state space is covered\nby acquired skills. A more detailed description can be found in Konidaris and Barto [3].\n"],"Page":2,"Number":1,"Type":"Figure","CaptionBB":[148,938,700,1013],"Height":1100,"Width":850,"DPI":100,"ImageBB":[158,848,694,925]}