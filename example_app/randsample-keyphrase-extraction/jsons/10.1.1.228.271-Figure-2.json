{"Caption":"Figure 2: Database cracking.","ImageText":[{"Text":"                               ","TextBB":[112.771,78.5847,352.983,93.217],"Rotation":0},{"Text":"                                     ","TextBB":[135.464,102.742,335.899,117.039],"Rotation":0},{"Text":"                               ","TextBB":[112.818,128.075,353.075,142.708],"Rotation":0},{"Text":"    ","TextBB":[109.451,175.075,140.446,189.708],"Rotation":0},{"Text":"   ","TextBB":[117.338,190.931,132.422,205.227],"Rotation":0},{"Text":"                           ","TextBB":[175.73,154.954,325.089,169.251],"Rotation":0},{"Text":"        ","TextBB":[153.729,175.075,215.765,189.708],"Rotation":0},{"Text":"                   ","TextBB":[228.911,175.075,376.137,189.708],"Rotation":0},{"Text":"   ","TextBB":[177.16,190.931,192.244,205.227],"Rotation":0},{"Text":"   ","TextBB":[294.867,190.931,309.952,205.227],"Rotation":0},{"Text":"                           ","TextBB":[203.497,213.577,357.145,227.874],"Rotation":0},{"Text":"    ","TextBB":[101.148,230.793,132.143,245.425],"Rotation":0},{"Text":"   ","TextBB":[144.551,230.793,167.797,245.425],"Rotation":0},{"Text":"     ","TextBB":[175.869,230.793,214.638,245.425],"Rotation":0},{"Text":"    ","TextBB":[225.728,230.793,256.723,245.425],"Rotation":0},{"Text":"               ","TextBB":[265.487,230.793,381.718,245.425],"Rotation":0},{"Text":"   ","TextBB":[109.035,249.046,124.12,263.343],"Rotation":0},{"Text":"    ","TextBB":[145.335,249.046,166.876,263.343],"Rotation":0},{"Text":"    ","TextBB":[184.171,249.046,206.436,263.343],"Rotation":0},{"Text":"    ","TextBB":[230.341,249.046,251.882,263.343],"Rotation":0},{"Text":"    ","TextBB":[312.487,249.046,334.751,263.343],"Rotation":0}],"Mention":["dexing mechanisms could then create and refine the recommended\nindex structures while minimizing additional workload.\nDatabase Cracking. Database cracking combines features of\nautomatic index selection and partial indexes. It reorganizes data\nwithin the query operators, integrating the re-organization effort\ninto query execution. When a column is queried by a predicate for\nthe first time, a new cracker index is initialized. As the column\nis used in the predicates of further queries, the cracker index is\nrefined by range partitioning until sequentially searching a partition\nis faster than binary searching in the AVL tree guiding a search to\nthe appropriate partition.\nKeys in a cracker index are partitioned into disjoint key ranges,\nbut left unsorted within each partition. Each range query analyzes\nthe cracker index, scans key ranges that fall entirely within the\nquery range, and uses the two end points of the query range to fur-\nther partition the appropriate two key ranges. Thus, in most cases,\neach partitioning step creates two new sub-partitions using logic\nsimilar to partitioning in quicksort [9]. A range is partitioned into 3\nsub-partitions if both end points fall into the same key range. This\nhappens in the first partitioning step in a cracker index (because\nthere is only one key range encompassing all key values) but is\nunlikely thereafter [10].\nThe example in Figure 2 shows data being loaded directly, with-\nout sorting, into an unsorted array. As a side-effect of answering a\nfirst query on the range \u201Cd \u2013 i\u201D, the array is split into three parti-\ntions: (1) keys before \u2018d\u2019; (2) keys that fall between \u2018d\u2019 and \u2018i\u2019; and\n(3) keys after \u2018i\u2019. Then a new query for range \u201Cf \u2013 m\u201D is processed.\nThe values in partition (1) can be ignored, but partitions (2) and (3)\nare further cracked on keys \u2018f\u2019 and \u2018m\u2019, respectively. Subsequent\nqueries continue to partition these key ranges until the structures\nhave been optimized for the current workload.\nUpdates and their efficient integration into the data structure are\ncovered in [11]. Multi-column indexes to support selections, tuple\nreconstructions and general complex queries are covered in [12].\nIn addition, [12] supports partial materialization and adaptive space\nmanagement via partial cracking. Finally, recent work [7] has sug-\ngested several optimizations for database cracking.\nAdaptive Merging. While database cracking functions as an in-\ncremental quicksort, with each query resulting in at most one or\ntwo partitioning steps, adaptive merging functions as an incremen-\ntal merge sort, with one merge step applied to all key ranges in\na query\u2019s result. Under adaptive merging, the first query to use a\ngiven column in a predicate produces sorted runs and each subse-\nquent query upon that same column applies to at most one addi-\ntional merge step. Each merge step only affects those key ranges\nthat are relevant to actual queries, leaving records in all other key\nranges in their initial places. This merge logic takes place as a side\neffect of query execution.\n","ing sorting for both partition types, represents the column-store im-\nplementation of the original adaptive merging algorithm (see exam-\nple in Figure 3). Given that we aim at avoiding the high investment\nof sorting all initial partitions, we do not consider the HS* variants\nany further, focusing on the remaining 6 variants HR* and HC*.\nFigure 4 depicts an example for Hybrid Crack Crack (HCC).\nWith the first query, the data is loaded into four initial partitions\nthat hold disjoint row ID ranges. (For ease of presentation, we omit\nthe row IDs in Figures 2 \u2013 5.) Then, each initial partition is cracked\non the given key range \u201Cd \u2013 i\u201D, and the qualifying key values are\nmoved into the gray-shaded final partition that also forms the re-\nsult of the first query. The second query\u2019s key range \u201Cf \u2013 m\u201D partly\noverlaps with the first query\u2019s key range. Hence, the final partition\n","part of the domain, i.e., to x% of the possible ranges we could\nquery. Here, we study more complex and general patterns where\nthe focus gradually shifts into target areas based on a specific pat-\ntern. These kind of scenarios represent more realistic workloads\nwhere the user explores and analyzes the data based on on-the-fly\nobservations.\nJump. In this experiment, we analyze a workload with a jump-\ning focus, i.e., the focus is initially on 20% of the data set, then\nafter 1000 queries it jumps to a different 20%, then to a different\n20% and so on. This represent a behavior where the user will even-\ntually study the whole data set but we do not need the complete\ndata set optimized in one go or at all times. Figure 12 shows such a\nworkload; as the query sequence evolves the workload focuses on\na small area of the domain and then the focus jumps to a different\narea.\n","Zoom. The zoom workload pattern reflects a zooming behav-\nior where progressive understanding during query processing leads\nto the actual point of interest, i.e., the workload stepwise zooms\ninto shrinking areas of interest. Figure 12 shows such an example.\nHere, the first 2000 queries are randomly spread over the whole key\nrange, the next 2000 queries focus on only the center 80% of the\nkey range, the next 2000 queries focus on the center 60% and so\non, until in the 5th step the target area has shrunk to the center 20%\nof the key range.\nDiscussion. Figure 13 shows the results. It is meant to pro-\nvide a high level visualization to provide insights of how adaptive\nindexing works in a variety of scenarios. For simplicity of presen-\ntation, we include results for the Crack Crack hybrid only. We use\ncolumns of 4âˆ—108 tuples and a query selectivity of 10%.\nSort and scan are insensitive to the workload and thus they pro-\nvide the same performance across the range of workloads tested.\n"],"Page":2,"Number":2,"Type":"Figure","CaptionBB":[162,270,318,288],"Height":1100,"Width":850,"DPI":100,"ImageBB":[95,77,388,265]}