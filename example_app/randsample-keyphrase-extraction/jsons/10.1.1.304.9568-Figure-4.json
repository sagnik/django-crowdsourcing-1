{"Caption":"Figure 4: Parameter selection when using SVM as the binary classifier","ImageText":[{"Text":"Given","TextBB":[368.167,126.469,406.762,141.621],"Rotation":0},{"Text":"(C,","TextBB":[412.011,126.469,433.05,141.621],"Rotation":0},{"Text":"γ)","TextBB":[435.508,126.469,450.06,141.621],"Rotation":0},{"Text":"1","TextBB":[351.167,159.47,358.742,174.621],"Rotation":0},{"Text":"fold","TextBB":[363.833,159.47,388.601,174.621],"Rotation":0},{"Text":"4","TextBB":[426.85,159.47,434.426,174.621],"Rotation":0},{"Text":"folds","TextBB":[439.517,159.47,470.337,174.621],"Rotation":0},{"Text":"5-fold","TextBB":[416.167,194.97,453.429,210.121],"Rotation":0},{"Text":"CV","TextBB":[458.678,194.97,481.039,210.121],"Rotation":0},{"Text":"decision","TextBB":[400,210.636,452.085,225.788],"Rotation":0},{"Text":"values","TextBB":[457.167,210.636,497.144,225.788],"Rotation":0},{"Text":"r","TextBB":[440.167,241.803,447,256.955],"Rotation":0},{"Text":"ij","TextBB":[447,247.597,455.763,257.88],"Rotation":0},{"Text":"validation","TextBB":[345.333,272.136,410.28,287.288],"Rotation":0},{"Text":"accuracy","TextBB":[415.529,272.136,473.021,287.288],"Rotation":0}],"Mention":["where A and B are estimated by minimizing the negative log-likelihood function, and fˆ are\nthe decision values of training data. Platt (2000); Zhang (2004) observe that SVM decision\nvalues are easily clustered at ±1, so the probability estimate (33) may be inaccurate. Thus,\nit is better to use CV decision values as we less overfit the model and values are not so\nclose to ±1. In our experiments here, this requires a further CV on the four-fold data (i.e.,\na second level CV).\nNext, for each instance in the validation set, we apply the pairwise coupling methods\nto obtain classification decisions. The error of the five validation sets is thus the cross-\nvalidation error at (C, γ). From this, each rule obtains its best (C, γ).2 Then, the decision\nvalues from the five-fold cross-validation at the best (C, γ) are employed in (33) to find the\nfinal A and B for future use. These two values and the model via applying the best param-\neters on the whole training set are then used to predict testing data. Figure 4 summarizes\nthe procedure of getting validation accuracy at each given (C, γ).\nThe average of 20 MSEs are presented on the left panel of Figure 5, where the solid line\nrepresents results of small sets (300 training\/500 testing), and the dashed line of large sets\n(800 training\/1,000 testing). The definition of MSE here is similar to (32), but as there is\n"],"Page":14,"Number":4,"Type":"Figure","CaptionBB":[189,307,659,324],"Height":1100,"Width":850,"DPI":100,"ImageBB":[343,123,499,289]}