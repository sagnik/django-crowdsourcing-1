{"Caption":"Figure 1: Average network classification accuracy","ImageText":[{"Text":"%","TextBB":[126.624,774.464,139.245,787.919],"Rotation":0},{"Text":"70","TextBB":[125.1,795.908,138.938,808.196],"Rotation":0},{"Text":"65","TextBB":[125.1,816.908,138.938,829.196],"Rotation":0},{"Text":"60","TextBB":[125.1,837.909,138.938,850.197],"Rotation":0},{"Text":"55","TextBB":[125.1,858.576,138.938,870.864],"Rotation":0},{"Text":"50","TextBB":[125.1,879.576,138.937,891.864],"Rotation":0},{"Text":"0","TextBB":[144.45,914.244,151.369,926.532],"Rotation":0},{"Text":"5","TextBB":[204.451,914.244,211.37,926.532],"Rotation":0},{"Text":"10","TextBB":[260.994,914.244,274.832,926.532],"Rotation":0},{"Text":"15","TextBB":[320.663,914.244,334.5,926.532],"Rotation":0},{"Text":"Epochs","TextBB":[221.414,934.705,265.113,946.993],"Rotation":0},{"Text":"(*","TextBB":[269.734,934.705,282.022,946.993],"Rotation":0},{"Text":"10","TextBB":[282.028,933.793,297.179,947.248],"Rotation":0},{"Text":"3","TextBB":[297.179,931.128,303.057,940.957],"Rotation":0},{"Text":")","TextBB":[303.751,934.705,309.134,946.993],"Rotation":0},{"Text":"20","TextBB":[380.664,914.244,394.501,926.532],"Rotation":0}],"Mention":["In a second experiment, vectors of numerically in-\ndexed documents were converted to weighted matri-\nces and further reduced using SVD, to infer the need\nfor representing co-occurrence of words in identify-\ning a document. The reduced vector space of 101\npseudo-documents was fed into the neural net for\ntraining. Then, a query together with 105 documents\nwas given to the trained neural net for simulation and\ninference purpose.\nFor the reduced vectors a wider range of values\ncould be tried. Thus 100, 200, . . . , 1000 epochs\nwere tried at the beginning of the experiment. The\nnetwork performance kept improving and the train-\ning was then allowed to go on for 2000, 3000,\n. . . , 10,000, 20,000 epochs thereafter. The average\nclassification accuracy was at an apex after 5,000\nepochs, as can been seen in Figure 1.\nThe neural net with the highest accuracy was se-\nlected for further analysis. As in the previous model,\ndocuments in the vicinity of the query were ranked\nusing the cosine similarity measure and the precision\non the test set is illustrated in the third column of Ta-\nble 3. As can be seen in the table, this system was\neffective with 60.0% eleven-point average precision\non the test set (each of the 16 queries was tested).\nThus, the performance of the reduced vector\nspace system was very much better than that ob-\ntained using the test set of the normal term docu-\nment matrix that resulted in only 10.5% average pre-\ncision. In both cases, the precision of the training set\nwas assessed using the classification accuracy which\nshows how documents with similar features cluster\ntogether (occur on the same or neighbouring nodes).\n"],"Page":6,"Number":1,"Type":"Figure","CaptionBB":[104,967,409,983],"Height":1100,"Width":850,"DPI":100,"ImageBB":[123,770,396,950]}