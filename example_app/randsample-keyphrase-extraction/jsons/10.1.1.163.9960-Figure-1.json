{"Caption":"Figure 1: Mechanism M","ImageText":[{"Text":"For","TextBB":[192.16,112.417,214.304,125.871],"Rotation":0},{"Text":"t","TextBB":[219.349,112.417,224.82,125.871],"Rotation":0},{"Text":"=","TextBB":[229.028,112.417,240.813,125.871],"Rotation":0},{"Text":"1,","TextBB":[245.025,112.417,256.806,125.871],"Rotation":0},{"Text":"2,","TextBB":[259.332,112.417,271.116,125.871],"Rotation":0},{"Text":".","TextBB":[273.646,112.417,277.855,125.871],"Rotation":0},{"Text":".","TextBB":[280.371,112.417,284.58,125.871],"Rotation":0},{"Text":".","TextBB":[287.11,112.417,291.319,125.871],"Rotation":0},{"Text":"With","TextBB":[219.421,143.689,253.513,157.144],"Rotation":0},{"Text":"probability","TextBB":[258.559,143.689,330.992,157.144],"Rotation":0},{"Text":"η(t),","TextBB":[336.046,143.689,365.578,157.144],"Rotation":0},{"Text":"explore:","TextBB":[370.628,143.689,420.779,157.144],"Rotation":0},{"Text":"Uniformly","TextBB":[258.79,174.96,325.754,188.414],"Rotation":0},{"Text":"at","TextBB":[329.284,174.96,342.752,188.414],"Rotation":0},{"Text":"random,","TextBB":[346.283,174.96,401.04,188.414],"Rotation":0},{"Text":"allocate","TextBB":[404.874,174.96,455.787,188.414],"Rotation":0},{"Text":"the","TextBB":[459.318,174.96,480.362,188.414],"Rotation":0},{"Text":"item","TextBB":[483.892,174.96,513.353,188.414],"Rotation":0},{"Text":"to","TextBB":[516.883,174.96,530.351,188.414],"Rotation":0},{"Text":"an","TextBB":[533.881,174.96,549.875,188.414],"Rotation":0},{"Text":"agent","TextBB":[553.406,174.96,589.177,188.414],"Rotation":0},{"Text":"i,","TextBB":[592.71,174.96,602.138,188.414],"Rotation":0},{"Text":"1","TextBB":[605.972,174.96,613.547,188.414],"Rotation":0},{"Text":"≤","TextBB":[617.757,174.111,629.542,188.414],"Rotation":0},{"Text":"i","TextBB":[633.75,174.96,638.97,188.414],"Rotation":0},{"Text":"≤","TextBB":[643.178,174.111,654.963,188.414],"Rotation":0},{"Text":"n.","TextBB":[659.171,174.96,672.474,188.414],"Rotation":0},{"Text":"p","TextBB":[258.79,206.232,266.413,219.687],"Rotation":0},{"Text":"it","TextBB":[266.414,211.337,274.665,221.167],"Rotation":0},{"Text":"←","TextBB":[279.565,205.384,294.717,219.687],"Rotation":0},{"Text":"0","TextBB":[298.926,206.232,306.502,219.687],"Rotation":0},{"Text":"With","TextBB":[219.421,237.503,253.513,250.957],"Rotation":0},{"Text":"probability","TextBB":[258.559,237.503,330.992,250.957],"Rotation":0},{"Text":"1","TextBB":[336.053,237.503,343.629,250.957],"Rotation":0},{"Text":"−","TextBB":[346.987,236.654,358.772,250.957],"Rotation":0},{"Text":"η(t),","TextBB":[362.139,237.503,391.671,250.957],"Rotation":0},{"Text":"exploit:","TextBB":[396.721,237.503,443.969,250.957],"Rotation":0},{"Text":"Randomly","TextBB":[258.79,268.775,326.763,282.23],"Rotation":0},{"Text":"allocate","TextBB":[331.809,268.775,382.737,282.23],"Rotation":0},{"Text":"the","TextBB":[387.783,268.775,408.827,282.23],"Rotation":0},{"Text":"item","TextBB":[413.887,268.775,443.348,282.23],"Rotation":0},{"Text":"to","TextBB":[448.393,268.775,461.862,282.23],"Rotation":0},{"Text":"an","TextBB":[466.907,268.775,482.901,282.23],"Rotation":0},{"Text":"agent","TextBB":[487.962,268.775,523.733,282.23],"Rotation":0},{"Text":"i","TextBB":[528.782,268.775,534.002,282.23],"Rotation":0},{"Text":"∈","TextBB":[538.211,267.927,548.313,282.23],"Rotation":0},{"Text":"argmax","TextBB":[552.521,268.775,601.806,282.23],"Rotation":0},{"Text":"i","TextBB":[601.806,275.245,605.809,285.075],"Rotation":0},{"Text":"{µ","TextBB":[606.501,267.927,623.207,282.23],"Rotation":0},{"Text":"it","TextBB":[623.207,273.88,631.458,283.71],"Rotation":0},{"Text":"(t)}.","TextBB":[632.15,268.775,661.191,282.23],"Rotation":0},{"Text":"p","TextBB":[258.79,300.047,266.413,313.502],"Rotation":0},{"Text":"it","TextBB":[266.414,305.152,274.665,314.982],"Rotation":0},{"Text":"←","TextBB":[279.565,299.199,294.717,313.502],"Rotation":0},{"Text":"t−1","TextBB":[314.919,295.898,334.195,305.728],"Rotation":0},{"Text":"k=1","TextBB":[314.919,307.359,336.368,317.189],"Rotation":0},{"Text":"y","TextBB":[339.585,300.047,347.014,313.502],"Rotation":0},{"Text":"ik","TextBB":[347.012,305.348,357.14,315.178],"Rotation":0},{"Text":"min{γ","TextBB":[360.653,300.047,401.325,313.502],"Rotation":0},{"Text":"k","TextBB":[401.325,305.348,407.449,315.178],"Rotation":0},{"Text":"(k),","TextBB":[408.436,300.047,432.795,313.502],"Rotation":0},{"Text":"γ","TextBB":[435.319,300.047,443.163,313.502],"Rotation":0},{"Text":"k","TextBB":[443.164,305.348,449.288,315.178],"Rotation":0},{"Text":"(t)}","TextBB":[450.275,300.047,475.106,313.502],"Rotation":0},{"Text":"−","TextBB":[478.47,299.199,490.255,313.502],"Rotation":0},{"Text":"t−1","TextBB":[509.618,295.898,528.895,305.728],"Rotation":0},{"Text":"k=1","TextBB":[509.618,307.359,531.067,317.189],"Rotation":0},{"Text":"p","TextBB":[534.283,300.047,541.906,313.502],"Rotation":0},{"Text":"ik","TextBB":[541.906,305.348,552.033,315.178],"Rotation":0},{"Text":"r","TextBB":[219.421,331.318,226.257,344.773],"Rotation":0},{"Text":"it","TextBB":[226.256,336.425,234.507,346.254],"Rotation":0},{"Text":"←","TextBB":[239.408,330.47,254.56,344.773],"Rotation":0},{"Text":"the","TextBB":[259.61,331.318,280.654,344.773],"Rotation":0},{"Text":"report","TextBB":[285.699,331.318,326.613,344.773],"Rotation":0},{"Text":"of","TextBB":[331.658,331.318,343.864,344.773],"Rotation":0},{"Text":"agent","TextBB":[348.925,331.318,384.696,344.773],"Rotation":0},{"Text":"i.","TextBB":[389.746,331.318,399.174,344.773],"Rotation":0},{"Text":"p","TextBB":[219.421,362.59,227.044,376.045],"Rotation":0},{"Text":"jt","TextBB":[227.043,367.695,236.689,377.525],"Rotation":0},{"Text":"←","TextBB":[241.586,361.742,256.738,376.045],"Rotation":0},{"Text":"0,","TextBB":[260.946,362.59,272.731,376.045],"Rotation":0},{"Text":"j","TextBB":[277.781,362.59,284.02,376.045],"Rotation":0},{"Text":"=","TextBB":[289.097,362.59,300.882,376.045],"Rotation":0},{"Text":"i","TextBB":[305.09,362.59,310.31,376.045],"Rotation":0}],"Mention":["We build our mechanism on top of a learning algorithm that estimates the expected utility of the\nagents. We refrain from an explicit description of the learning algorithm. Rather, we describe\nsufficient conditions for a learning algorithm that can be extended to a mechanism with all the\nproperties we seek (see section 4.1). In section 5.1 and 5.2 we give two examples of environments\nwhere learning algorithms satisfying these sufficient conditions exist.\nThe mechanism randomly alternates between two actions: exploration and exploitation. At time\nt, with probability η(t), η : N → [0, 1], the mechanism explores i.e. it allocates the item for free\nto an agent chosen uniformly at random. With the remaining probability, the mechanism exploits.\nDuring exploitation, the item is allocated to the agent with the highest estimated expected utility.\nThen, the agent reports her utility to the mechanism and the mechanism determines the payment.\nWe first formalize our assumptions about the learning algorithm and then we discuss the payment\nscheme. The mechanism is given in Figure 1.\n"],"Page":7,"Number":1,"Type":"Figure","CaptionBB":[339,404,510,420],"Height":1100,"Width":850,"DPI":100,"ImageBB":[166,99,685,397]}